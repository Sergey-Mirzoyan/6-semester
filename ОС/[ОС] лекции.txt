21.02.15 ------------------------------------------------------------

Напоминание, компьютер = проц+оперативка, всё остальное - внешние устройства.

Компьютеры до сих пор работают по схеме фон Неймана, три типа сигнала: передача данных, передача адресов, передача сигналов управления. Все многообразие устройств ввода-вывода сведено к нескольким основным принципам.
Прежде всего, устройство подключается к системе - оно должно взаимодействовать с процессором, передавать и получать информацию. Реализуется с помощью портов - параллельных и последовательных. При этом существуют устройства, которые "не очень хоорошо" подключать к портам, существует два принципа: IO Mapping \ Memory Mapping.
	ИО маппинг - реализация взаимодействия с внешними устройствами через порты ввода\вывода; в системе должно существовать два адресных пространства - ОП и портов ВВ. Для реализации необходимо иметь команды работы с портами ВВ, в ассемблере это IN, OUT.
	Мемори маппинг - отображение на память. Речь идёт о регистрах контроллеров устройств - они отображаются на память, в результате с внешним устройством можно работать используя команды работы с памятью MOV.
Для передачи информации используются шины - ISA, PCI, PCI-express. ОЗУ должно быть сопоставимо с процессором по быстродействию.
В основу компьютеров положен принцип распараллеливания - когда процесс запрашивает ввод\вывод, он блокируется (ВУ достаточно медленные); супервизор с помощью драйвера инициирует работу ВУ и переходит на выполнение другой работы. Управление ВУ берёт специальное устройство контроллер (адаптер); контроллер - устройство в составе ВУ, адаптер - устройство на материнской плате.

Чтобы процессору не требовалось рутинно опрашивать ВУ о готовности, вводятся аппаратные прерывания. При этом процессор и ВУ заинтересованы в том, чтобы иметь параллельный доступ к памяти. Используется bus mastering.

Схема PIK устарела, сейчас используются APIK и MSI. МСИ существует в двух вариантах: для PCI2.2 - MSI; PCI3.0 - MSI-X. Техника МСИ эквивалентна Edge-triggered - срабатыванию по фронту. Есть два типа срабатывания: по уровню (level-triggered) и по фронт.

cat/proc/interrupts
Выводится информация о выделенном векторе для конкретного устройства и способе прерываний.
	CPU0		CPU1		CPU2		CPU3
0:	14175		0			17408		0		IO-APIC-edge timer
1:	123			310			0			37		IO-APIC-edge keyboard
...
12:	41			0			0			813		IO-APIC-edge PS/2 mouse
193:	30		0			0			0		PSI MSI aic79xx

Сообщение прерывания - определенное значение, которое устройство пишет в специально отведенное ему адресное пространство по определенному адресу, чтобы вызвать прерывание работы процессора.

Если использовать технику прерываний, то на каждой передаче информации на каждом переданном символе будет возникать прерывание; символ через регистры процессора помещается в соответствующие ячейки ОП. Параллельность работы обеспечивается огромным быстродействием процессора.

DMA (ПДП) - Direct Memory Access (начало в последней лекции прошлого сема).

(фото ~12:48 / диаграмма 1)

Контроллер ПДП - медленное устройство. Если процессор не занят никакой работой, то перекачка информации идёт через процессор; тем не менее, в современных системах это зачастую не так.

(диаграмма 2)

При появлении команд память\регистр, работает прямой доступ к памяти; это осуществляется путем захвата шины. Процессор не может быть отключен от шины на длительное время: существует три режима ДМА.
1) пакетный (burst) - получив доступ к шине, контроллер байт за байтом передает весь блок данных. На это время процессор отключается от системной шины. Также режим называется block transfer mode.
2) кража циклов (cycle stealing) - используется, если процессор не может быть блокирован на длительное время. В этом режиме для доступа к системной шине используются те же сигналы, что и в пакетном режиме - запрос ПДП (BusRequst) и подтверждение ПДП (BusGrant). После БР передаётся 1 байт и контроллер над системной шиной возвращается процессору сигналом БГ.
3) прозрачный режим (transparent mode) - контроллер ПДП передает данные в те моменты, когда процессор системную шину не использует.

Эти моменты необходимо выделить и проверять. Существует цикл выполнения команды:
(диаграмма 3)

ПДП - не прерывание и не требует переключения контекста. Но данный режим требует, чтобы аппаратно определялись моменты, когда процессор не использует системную шину - что усложняет аппаратуру.
Основное достоинство - наличие нескольких точек в цикле выполнения команды, когда может выполняться ПДП. На скорость выполнения программы это не влияет существенно.

PCI-архитектура не имеет центрального контроллера DMA, в отличие от ISA. Соответственно, в современных системах используется Ultra-DMA.
Любой компонент ПСИ может запросить управление шины. Если несколько устройств одновременно запрашивают контроль, то арбитр южного моста выбирает хозяина (ведущего, master) шины. Устройство, успешно осуществившее захват шины самостоятельно выставляет на шину сигналы адреса и управления, и управляет передачей данных по шине.

Чтобы подчеркнуть совместимость: некоторые старые устройства ПСИ (например, звуковые карты SoundBlaster) использовали старый контроллер ДМА для шин ИСА. Такой подход является устаревшим, но поддерживается для обеспечения полной совместимости программного обеспечения с драйверами версии SoundBlaster для шины ИСА. Такая поддержка называется Distributed DMA и реализуется аппаратно или на устройстве, или в логике моста PCI-ISA - то есть, в ПСИ-системах размещена старого контроллера.


PCI-DMA обмен.
Начинается по инициативе Integrated Drive Electronics-контроллера.
а) контроллер посылает запрос арбитру шины и, получив разрешение, захватывает шину
б) захватив шину, контроллер управляет передачей  данных по шине
в) данные передаются южным мостом северному мосту, который передаёт их из или в память.
Шина памяти обслуживает процессор и ИДЕ-контроллер поочередно под управлением северного моста. Нормальный (штатный) ДМА-обмен заканчивается прерыванием от контроллера.

Область обмена - задается особым дескриптором, который называется Physical Region Descriptor. Массив таких дескрипторов формирует таблицу PRD-table.

В ОС со страничной виртуальной памятью (винда, линукс и тд) непрерывный диапазон виртуальных адресов может быть реализован физическими страницами, расположенными в памяти в произвольном порядке. Реализация ДМА в этом случае представляет довольно сложную задачу.



28.02.15 ------------------------------------------------------------

В новых системах ПДП используется, DMA-express (перекачка данных с диска и на диск), но идет изменение систем.

Программные принципы управления внешними устройствами.
Основной - transparent principal, украшающие принципы. Система должна предоставить пользователю минимальный достаточный набор функций, с помощью которых можно работать со всеми внешними устройствами. Основная идея - в системе всё файл.

Файловые системы.
ФС - некоторая организация данных и метаданных на устройстве хранения. Не уточняются форматы, способы хранения. Система позволяет организовать хранение данных. Поскольку нет уточнений, то любой разработчик может сам организовать для себя хранение данных некоторым образом - ФС может быть много, но любая ОС должна предоставлять возможность работы с файлами. В *никсах ОС предоставляет возможность работы с любой из файловых систем, которые зарегистрированы в системе.

Существует общий подход при работе с файлами.
	|
Запрос к файлу
	V
[Символьный уровень]
	V
[Базовый уровень]
	V
[Уровень проверки прав доступа]
	V
[Логический уровень]
	V
[Физический уровень]

Система должна позволять единообразно обращаться к файлам - выделяется символьный уровень - уровень именования файлов (с помощью символьных строк). ФС могут иметь иерархическую организацию каталогов (дос, винда, никсы); неиерархическую организацию. Полное имя составляется из пути к файлу и его имени. При этом никсы не оперируют именами файлов при работе - они предоставляются только для удобства пользователя.
Базовый - уровень собственно идентификации файла в системе. У файла есть дескриптор - содержит информацию, необходимую для доступа к файлу, и все имена данного файла (хард-линки).
Логический - уровень доступа к информации в файле. В наших системах существует два способа доступа: последовательный и прямой; поддерживается два типа файлов - байт-ориентированные и блок-ориентированные. Существует два типа устройств - символьные и блочные. В байт-ориентированных файлах возможно чтение информации по байтам; append осуществляет дозапись в конец файла. В блок-ориентированных файлах есть возможность обратиться к конкретному блоку, поскольку его адрес может быть вычислен.
Физический уровень - файлы находятся на физическом внешнем устройстве. Обращение идет через подсистему ввода-вывода "обычным образом".

Основная идея *никсов - возможность смонтировать любую файловую систему. Используется метод vfs/vnode - VirtualFileSystem/VirtualNode.

Архитектура VFS:
(диаграмма 1)
Для подключения ФС, она должна быть зарегистрирована в системе, а затем смонтирована.
mount( spec, dir, flags, type, dataptr, datalen );
	спек - имя устройства, представляющего ФС;
	дир - полное имя каталога, являющегося точкой монтирования;
	тип файловой системы
	датаптр - указатель на дополнительные аргументы, зависящие от ФС.

Интерфейс внод\вфс создан на концепциях ООП - классы и объекты. На основе любого класса можно создать один или более порожденных классов (наследников). Ядро размещает по одному объекту ВФС для каждой активной ФС - любой объект ВФС соответствует какой-то файловой системе.

(диаграмма 2)

Пример инициированного массива структур VFSSw
struct vfssw[] = {
	{0,0,0,0},
	{...},
	{ufs, ufsinit, &ufs_vfsops, 0},
	{s5, vx_init, &vx_vfops, 0},
	...
};
Пример демонстрирует создание ФС в файле, расположенном в уже существующей ФС. Необходимо создать файл заданного размера с помощью команды dd (duplicate).
$ dd if=/dev/zero of=file.img bs=lk count=10000 10000+0 records in 10000+0 records out
$
Создаётся файл .имг размером 10мегабайт. Далее файл необходимо связать с блочным устройством, используется заглушка-loop:
$ losetup /dev/loop0 file.img
$
После этой команды файл, который выглядит как блочное устройство, представлен как /dev/loop0 . Далее на этом устройстве создается непосредственно файловая система
$ mke2fs -c /dev/loop0 10000
  mke2fs 1.35(28-feb-2004)
  max_blocks 1024000, rsv_group = 1250, rsv_gdb=39
  FileSystem label=
  OS type: Linux
  Block size=1024 (log=0)
  Fragment size=1024 (log=0)
  2512 inodes, 10000 blocks
  500 blocks (5% reserved for super user)
  ...
$ mkdir /mnt/point1
$ mount -t ext2 /dev/loop0 /mnt/point1
$ ls /mnt/point1
  lost+found 
$
В результате файл .имг представленный устройством /dev/loop0 смонтирован в точке /mnt/point1 с помощью команды mount. Указан тип файловой системы ext2. После этого можно обращаться к точке монтирования как к новой файловой системы. Процесс можно продолжить.

(диаграмма 3)

Каждая ФС - объект типа struct vfs. Структура, описывающа ВФС, имеет следующий вид:
struct vfs
{
	struct vfs *vfs_next;
	struct vfsops *vfs_ops; //массив операций, возможных на ФС
	struct vnode *vfs_vnodecovered; //структура внод, смонтированная на конкретной ФС
	int vfs_fstype; //индекс типа ФС
	cadd_t vfs_data;
	dev_t vfs_dev;
	...
};
struct vnode
{
	ushort v_flag;
	ushort v_count; //счетчик ссылок
	struct vfs *vfsmountedhere; //используется для точек монтирования
	struct vnodeops *v_ops; //перечисление операций, которые можно выполнять над ФС
	struct vfs *vfsp; //ФС, к которой относится данная структура
	...
};

Чтобы управлять файлами, ФС имеет 4 основных типа объектов:
	superblock - каждый суперблок представляет определенную смонтированную ФС
	inode - файловый индекс, определяющий конкретный файл
	dentry - элемент каталога (directory entry), определяет путь
	file - представляет открытый файл
Система различает файлы, просто лежащие на диске, и с которыми идет работа; создается ссылка из дескриптор файла.



02.03.15 ------------------------------------------------------------

typedef struct vfs
{
	struct vfs* vfs_next;
	struct vfsops* vfs_op; //массив структур операций
	struct vnode *vfs_vnodecovered;
	...
	int vfs_fstype; //тип файловой системы
	dev_t vfs_dev; //device of mounted vfs
	u_long vfs_bcount; //счетчик блокировок
} vfs_t
Голова списка находится в глобальной переменной root_up

Функция int vfs_mount(vfsp) - монтирвание виртуальной файловой систеы.

struct vnode
{
	struct uvm_object v_uobj;
	kcondvar v_cn; //используется для синхронизации
	voff_t v_size //размер файла
}



07.03.15 ------------------------------------------------------------

Для поддржки никсами любых файловых систем, в ОС реализован интерфейс VFS-vnode. Были рассмотрены основные структуры, связанные с этой файловой системой.

Анализ системного вызова open
Реализован в fs/open.c : sys_open(); hlp_open(); open_namei()
опен_намеи - функция заполняет структуру nameidata, которая содержит dentry, vfsmount
dentry_open() - используя заполненную дентри и вфсмоунт, заполняет структуру file и связывает их между собой.
Действие связано со считыванием инода, который содержит информацию о физическом расположении файла на диске. При считывании инода, значение дентри присваивается посредством функции d_add(dentry, inode).

Таким образом, при открытии файла вызывается функция iget(), выполняющая следующие действия:
1. Пытается найти инод в хэш-таблице по номерам суперблока и инода (данный поиск выполняется с использованием блокировки inodelock). Если инод найден, то увеличивается его счетчик ссылок; если счетчик перед инкрементом был равен нулю и инод не "грязный" (dirty - измененный), то он удаляется из любого списка в котором находится, и вставляется в список inode_in_use.
2. Если инод на текущий момент заблокирован, то выполняется ожидание в очереди к иноду. игет() гарантирует возврат незаблокированного инода.
3. Если поиск по хэш-таблице не увенчался успехом, то вызывается get_view_inode(), которой передается указатель на место в ХТ, куда должен быть вставлен инод.
4. гетвьюинод выделяет память под новый инод. При этом блокировка инодлок сбрасывается. Поскольку блокировка была сброшена, то производится повторный поиск в ХТ, и если на этот раз инод найден, то он возвращается в качестве результата. Новый (только что распределенный) инод уничтожается. Если же инод не был найден в ХТ, то вновьсозданный инод инициализируется необходимыми значениями.

О хранении файлов в линухе
Директории, обычные файлы, софтлинки, сокеты, блочные и символьные файлы, программные каналы (пайпы). Никсы поддерживают "очень большие файлы" за счет следующей структуры.
[0][1] ... [14]
0-11 - непосредственная адресация, 12 блоков
12: 1024 записи, простая косвенная адресация
13: 1024 блока по 1024 блока, все вместе используются для двойной косвенной адресации
14: 1024 блока по 1024 блока, каждый ещё по 1024 блока, для тройной косвенной адресации.
Каждый новый уровеь - дополнительное время, вся информация хранится на диске.

Открытые файлы
Можно провести аналогию с исполняемой программой; для исполняемости программы процессу выделяются ресурсы. Если процесс желает начать работать с файлом, он должен его открыть - при этом создаются соответствующие структуры, которые связываются с теми структурами, которые были рассмотрены ранее.
Открытие файла вызовом open(const char* pathname, int flag, .../*mode_t mode*/) в #include <fcntl.h>. Многоточие в стандарте ИСО-Си указывает, что количество остальных аргуметов и их типы может варьироваться. fd = open( "myfile", O_RDWR|O_CREAT|O_EXCL, 0644 ) - флаг организуется или-объединением констант из фкнтл.х. Опен возвращает файловый дескриптор - целое число. Дескриптор применяется как идентификатор файла и затем пердается системным вызовам read\write.
о-креат - если файл не существует, то будет создан; требует третьего аргумента, который определяет права доступа к файлу. о-ексл - приводит к возврату ошибки, если файл уже существует (проверка существования и создание выполняются атомарно).
Получить файловый дескриптор можно через функцию int fileno(FILE *fp) библиотеки stdin.h. ФД - объект процесса, который содержит указатель на объект открытого struct file и набор флагов. Система поддерживает следующие флаги:
	FCLOSEXEC - указывает ядру на необходимость использовать дескриптор при вызове процессом системного вызова exec
	U_FDLOCK - применяется для блокировки файла.

	(диаграмма 1, 2)
Один и тотже внод может быть открыт несколько раз - на один файл ссылаются два раза (количество ссылок 2)
Система отслеживает связи файлов. Один и тотже файл может иметь много открытых соединений - может быть открыт разными процессами несколько раз. При наличии указателя на внод, можно получить указатель на инод - доступ к физическим записям на любом запоминающем устройстве.


Разреженные файлы
Никсы позволяют создавать файлы, логический размер которых превышает физический. Такие файлы могут быть удобны и используются когда необходимо отобразить на файл какую-либо незаполненную структуру данных (например матрицу с большим количеством элементов.
Наглядным примером разреженных файлов являются файлы core.dump.

#include <stdio.h>
#include <string.h>
#define SIZE 0x1000000
int main(int argc, char *argv[])
{
	FILE *f = fopen(argv[1] "w");
	if ( f == NULL )
		{ printf("error\n"); return 1;}
	fwrite( argv[1], 1, strlen(argv[1]), f );
	fseek( f, SIZE, SEEK_CUR );
	fwrite( argv[1], 1, strlen(argv[1]), f );
	fclose(f);
}
На диске будет создан файл; ls -al сообщит, что размер файла >16мегабайт. Однако с помощью команды du <file> получим, что на диске файл занимает ~24 байта. Причина появления пропусков - смещение через функцию фсик в область после конца файла. Выход за пределы файла через фсик является стандартным способом получения разреженных файлов.
При вызове фсик в данной программе, указатель файла находится в конце файла; SEEK_CUR указывает отсчитывать смещение от текущей позиции - в файле образуется пропуск. При чтении разреженных файлов, могут возвращаться блоки, заполненные нулями.

Файловая система proc
Проц (так же как дев и некоторые другие ФС) не является монтируемой ФС, а представляет собой интерфейс, который позволяет приложениям читать и изменять данные в адресном пространстве ядра, а также в адресном пространстве других процессов и тп, используя стандартный интерфейс файловой системы и системных вызовов.
Управление доступом к адресному пространству ядра происходит с помощью обычных прав доступа рид\врайт\екзек. По-умолчанию запись и чтение файлов проц разрешены только для владельцев этих файлов. В ФС Проц данные о каждом процессе хранятся в поддиректории /proc/<PID> - имя поддиректории является числовым значением идентификатора процесса. В поддиректории процесса хранятся поддиректории, содержащие данные о процессе.

Элемент					Тип						Содержание
	cmdline			файл					указывает на директорию процесса
	CWD				символьная ссылка		-''-
	environ			файл					список окружения процесса
	exe				симв.ссылка				указывает на образ процесса (его файл)
	fd				директория				ссылки на файлы, используемые процессом (открытые им файлы)
	root			симв.ссылка				указывает на корень файловой системы процесса
	stat			файл					информация о процессе

Процесс всегда может получить доступ к собственной поддиректории с помощью getpid() - можно узнать идентификатор и сконструировать путь поддиректории. Другой способ - использовать ссылку self: /proc/self , в которой находится каталог с данными.

Программа печатает информацию об окружении.
#include <stdio.h>
#define BUFSIZE 0x100
int main(int argc, char *argv[])
{
	char buf[BUFSIZE];
	int len, i;
	FILE *f = fopen( "/proc/self/environ", "r");
	while((len = fread(buf, 1, BUFSIZE, f)) > 0)
	{
		for (int i=0; i<len; ++i)
			if (buf[i] == 0)
				buf[i] = 10;
		buf[len] = 10;
		printf( "%s", buf );
	}
	fclose(f);
	return 0;
}
Строки разделяются не символами перевода строки, а нулями. Все файлы Проц являются виртуальными - они не существуют ни на каком носителе, а генерируются кодом ядра при каждом обращении для чтения к файлу proc. Проц - текстовый файл. Например, команда ls -pci или -apm показывает информацию из /proc/pci или /proc/apm. Пси - информация о текущих устройствах, подключенных к шине PCI; APM - состояние батареи.



21.03.15 ------------------------------------------------------------

Назначение ФС проц - отражать информацию о ядре в пользовательском режиме, дабы можно было получать информацию о функциях и событиях в ядре. Файлы и поддиректории могут создаваться, регистрироваться и удаляться динамически. Они используют
struct proc_dir_entry
{
	unsigned short low_ino;	//инод номер файла
	unsigned short namelen;
	const char *name;		//имя файла
	mode_t mode;			//режим доступа к файлу
	nlink_t nlink;			//количество ссылок
	uid_t uid;
	//...
	struct proc_dir_entry *next, *parent, *subdir;
	void *data;
	int (*get_info)(buffer, start, off, count);
	int (*read_proc)(buffer, start, off, count, eof, data);
	int (*write_proc)(file, buffer, count, data);
	//...
	int deleted;
};

Существует процедура создания:
struct proc_dir_entry* create_proc_entry(const char *name, mode_t mode, struct proc_dir_entry *base);
create_proc_entry(name, mode, parent); - создаст файл имени нейм (может быть указан относительный путь), с флагами свойств файла, и с указанием на структуру, в которой должен появиться файл. Мод чаще всего устанавливается в 0. После этого можно установить указатель на нужные данные и ввести процедуры обработки, чтения и записи для файла.
Попробуем создать /проц/нет/тест
te = create_proc_entry( "test", 0600, proc_net ); //test_entry
te->nlink = 1;
te->data = (void*)&test_data;
te->read_proc = test_read_proc;
te->write_proc = test_write_proc;
Для удаления можно воспользоваться функцией remove_proc_entry(name, parent); нужно передавать относительный пусть и структуру, в которой находится нейм.

Также есть функция, которая позволяет создавать директории: struct proc_dir_entry* proc_mkdir(const char* name, proc_dir_entry* parent); используется для создания поддиректории.

Часто требуется создавать файлы для отображения информации - достаточно зарегистрировать функцию для обращения к файлу за чтением. Это будет функция 
proc_dir_entry* create_proc_read_entry(const char* name, mode_t mode, proc_dir_entry* base, read_proc_t* read_proc, void* data;

(диаграмма 1)

access_ok(type, addr, size) - проверяет, что адрес принадлежит пространству пользователя а не едра, (тайп - VERIFY_READ, VERIFY_WRITE)
копи ту юзер - должна сначала проверить доступность указателя пространства пользователя, и только после этого выполнить запись.


Система ввода-вывода и её "украшающие принципы".
Ось - набор алгоритмов, которые скрывают детали аппаратного обеспечения и создают более "симпатичное" окружение. Raphael Finkel - An Operating System, Vade Mecum.
С любым внешним устройством пользователь использует тот же набор функций, что и для обычных (regular) файлов.

Вопрос разработки подсистем ВВ - один из сложнейших. Более 50% инструкций ядра связано с работой с внешними устройствами; при этом абсолютное большинство программ, связанных с управлением ВВ, являются подпрограммами ядра.
Задача ОС - скрыть или сделать невидимыми для пользователя детали взаимодействия приложений с внешними устройствами. Система должна предоставить пользователю набор команд, который не зависит от того, с каким устройством должно взаимодействовать приложение. При этом основное правило - приложение не может напрямую обратиться к ВУ;  все обращения возможны только из такназываемого привелигированного режима. Необходимо определить основные принципы, которые обеспечиывает ОС при работе с ВУ.
1. Эффективное управление  всем многообразием устройств ввода-вывода. Под эфективным понимается  такое взаимодействие процессора\процессоров с ВУ, при котором минимизируется время, затрачиваемое центральным процессором на управление внешними устройствами.
2. Система должна распределять внешние устройства между процессами или обеспечивать доступ к устройствам ввода множества параллельно выполняющихся процессов.
3. Система должна скрывать особенности работы отдельных устройств путём предоставления единообразного интерфейса без учета физических особенностей этих устройств и их технических характеристик. Пользователь должен мочь работать со всем многообразием ВУ с помощью ограниченного набора команд. Использовать стандартные потоки ввода-вывода и логические имена.
4. Возможность подключения\удаления дополнительных устройств без перезагрузки системы.

Никсы поддерживают единый интерфейс доступа к файлам и ВУ с помощью понятия device file (файл устройства) - это специальный файл, сопоставленный с определенным устройством. По соглашению, все девфайлы находятся в каталоге /dev. С точки зрения пользователя, девфайл не отличается от обычного - его можно открыть, закрыть, читать или писать данные.

Основные функции управления устройствами.
1.Отслеживание состояния всех устройств. Требуется наличие в системе специальных программных механизмов. Дабы система могла управлять ВУ, она должна иметь информацию об оном - в самом общем случае, информация хранится в блоке управления устройством (unit control block).
2.Принятие решения, кому, когда и на какой срок выделить устройство. Принятие решений зависит от стратегии распределения устройств - примером может служить стратегия максимального эффективного использования.
Существует три основных способа использования устройства:
а) закрепленные устройства; такие монопольно используются одним процессом
б) разделяемые устройства; могут совместно использоваться несколькими процессами
в) виртуальные устройства; одно физическое устройство моделируется с помощью другого. Пример виртуализации: SPOOLing, Simultaneous Peripheral Operations On Line. Создается видимость разделения устройства с последовательным доступом параллельными процессами.
3.Выделение устройства - связано с физическим приписыванием устройства процессу. Кроме него процессу должны быть также выделены соответствующие блоки и каналы.
4.Освобождение устройства. Устройство должно быть возвращено в пул свободных ресурсов данного типа - изменение системных таблиц, указателей и тп.

Подсистема ввода-вывода представляет часть ядра, управляющую аппаратно-независимой частью операций ввода-вывода и взаимодействующую с драйверами устройств для обработки аппаратно-зависимых операций. Подсистема В\В также отвечает за именование устройств и их защиту, предоставляя прикладным программам единый интерфейс доступа ко всем устройствам системы.


Различают три вида файлов: 1.Обычные (регулярные), 2.каталоги (директории), 3.специальные файлы: байт- и блок-ориентированные. Иерархия корневой файловой системы практически универсальна; в различных версиях оси, корневая файловая система включает следующий классический набор каталогов и файлов:
* boot - программа начальной загрузки ядра или автономной загрузки других ОС
* unix - файл, содержащий программу ядра ОС
* bin - каталог команд: ar, cat, dd, find, mkdir, rmdir, ...
* dev - каталог специальных файлов: fd0, lp0, null, mem, mouse, ... файлов устройств
* etc - каталог административных команд и таблиц: init, fseek, fstab, mount, ...
* lib - каталог основных библиотек: libc.a, libm.a ...
* tmp - каталог временных файлов
* mnt - каталог монтирования пользовательских файловых систем
* usr - каталог со следующими подкаталогами:
	adm (каталог файлов системного учета и администрирования: cron, syslog),
	bin (каталог инструментальных средств),
	lib (каталог дополнительных библиотек),
	man (каталог страниц оперативного руководства, man1..man8),
	include (каталог заголовочных файлов с и с++)
Специальные файлы обеспечивают унифицированный доступ к перифирийным устройствам и связь между файловой системой и драйверами. Такая интерпретация специальных файлов обеспечивает доступ к ВУ аналогично доступу к обычным файлам.



28.03.15 ------------------------------------------------------------

Рассмотрим сам каталог /dev.
/dev/fd/ содержит файлы 0, 1, 2 - это stdin, stdout, stderr. В некоторых системах подкатолог /фд может опускаться, эти файлы могут находиться непосредственно в деве; /dev/stdin
Напоминание - имеется только два типа файлов устройств. Символьный - небуферизуемый файл; блочный - буферизуемый.

Связь имени файла с конкретным устройством обеспечивает индексный дескриптор. В юниксе: struct dinode; тип специального файла задает поле di_mode. В линуксе: kdev_t i_dev; kdev_t i_rdev.
Взаимодействие программ осуществляется по следующей схеме:

(диаграмма1)

При этом в винде происходит разделение драйверов на типы функциональные и тп. Юникс рассматривает собственные драйвера, а не поставляемые разработчиком.
Драйвер в составе системы может решать более общие задачи; задача драйверов "нижнего уровня" - управление устройствами в соответствии с особенностями их конструкции. Используют специальные команды по управлению ВУ, освобождая высшие уровни от "знания" специфики работы устройства.

Драйвер - часть кода ядра, предназначенная для управления конкретным устройством. Обычно драйверы содержат последовательность команд, специичных для своего устройства. В линуксе драйверы бывают трёх типов:
1. драйверы встроенные в (монолитное) ядро. Соответствующие устройства автоматически обнаруживаются системой. Например: VGA контроллер, контроллеры IDE, материнская плата, последовательные и параллельные порты, USB-порты.
2. драйверы как загружаемые модули ядра. Часто используются для управления такими устройствами, как SCSI-адаптеры, звуковые и сетевые карты.
Файлы модулей ядра располагаются в подкаталогах /lib/modules/; обычно при установке системы задается список модулей, которые будут автоматически подключаться на этапе загрузки. Список загружаемых модулей хранится в файле /etc/modules; в файле /etc/modules.conf хранится перечень опций для таких модулей. Для редактирования используются специальные скрипты.
Для подключения и отключения модулей в системе используются специальные утилиты. lsmod - список загруженных модулей; insmod - загрузка или установка модуля из командной строки; rmmod - выгрузка или удаление; modprobe - автоматически загружает модули. Чтобы отобразить текущую конфигурацию можно modprobe -c выведет информацию о модулях символьных устройств.
3. код драйверов третьего типа делится между ядром и специальной утилитой. У принтера ядро отвечает за взаимодействие с параллельным портом, а формирование управляющих сигналов осуществляет демон печати lpd. Демон использует специальную программу-фильтр.

В системе файлы-устройств идентифицируются двумя положительными числами major_device_number и minor_ . Старший номер устройства обычно идентифицирует его тип. Младший номер идентифицирует конкретное устройство в ряду устройств с одним старшим номером.
Старшие и младшие номера могут определяться как константы в коде драйвера или получаться динамически при установке драйвера в системе. В первом случае если номера уже заняты, будет возвращена ошибка. Функции назначения динамически - резервируют назначенные номера устройств; в результате динамические номера не могут использоваться другими модулями.

Список старших номеров можно найти в /usr/include/linux/major.h
1	оперативная память
2	дисковод гибких дисков
3	первый контроллер ИДЕ-дисков
4	терминалы
5	терминалы
6	принтер (параллельный порт)
8	SCSI диски
13	мышь
14	звуковые карты
22	второй контроллер IDE-дисков
Файлы устройств одного типа имеют одинаковые имена и различаются по номеру который добавляется в конец имени - сетевые платы eth0, eth1, eth2 и так далее
ls -l в каталоге /dev/ выдаст список спецфайлов, для которых вместо размера файла будут выведены два числа через запятую. ls-l /dev/ | grep "^c" выведет список файлов символьных устройств; cat /proc/devices даст старшие номера устройств, известные ядру.

Для регистрации символьного устройства можно пользовать int register_chrdev(unsigned int major, const char *name, const struct file_operations *fops) - регистрирует устройство, заданное именем и старшим номером. Если мажор==0, то старший номер назначается. Функция связывает структуру файловых операций с устройством.
В случае назначения старшего номера, функция возвращает число, равное присвоенному номеру. Если мажор!=0 - возврат 0 успешное завершение, и возврат <0 ошибка. Переданное имя - имя модуля, используется для идентификации в файле /sys/devices
В результате спецфайл устройства будет зарегистрировано и связано с определенным старшим номером; младший номер может находиться в диапазоне 0..255.

Структура file_operations для ядра2.6.32 выглядит следующим образом:
struct file_operations
{
	struct module *owner;
	loff_t	(*llseak)	(struct file*, loff_t, int);
	ssize_t	(*read)		(struct file*, char*, size_t, loff_t*);
	ssize_t	(*write)	(struct file*, const char*, size_t, loff_t*); //КОНСТ чар!
	int		(*readdir)	(struct file*, void*, filedir_t);
	unsigned int (*poll)(struct file*, struct poll_table_struct*);
	int		(*ioctl)	(struct inode*, struct file*, unsigned int, unsigned long);
	int		(*mmap)		(struct file*, struct vm_area_struct*);
	int		(*open)		(struct inode*, struct file*);
	int		(*flush)	(struct file*);
	int		(*release)	(struct inode*, struct file*);
	int		(*fsync)	(struct file*, struct dentry*, int datasync);
	int		(*fasync)	(int, struct file*, int);
	int 	(*lock)		(struct file*, int, struct file_lock*);
	ssize_t	(*readv)	(struct file*, const struct iovec*, unsigned long, loff_t*);
	ssize_t	(*writev)	(struct file*, const struct iovec*, unsigned long, loff_t*);
};
Содержит указатели на функции, которые должны выполнять какие-то действия с устройством - открытие, чтение, запись и так далее. Овнер - указатель, идентифицирующий модуль, который выполняет функции из данной структуры.
Опен получает нетолько файл, но и инод - при открытии файла на чтение\дозапись, если файл уже создан, структура файла будет содержать указатель на инод. При пересоздании, инод будет создан заново, старый потеряется.
Аналогично для релиза.
фсинк и фасинк отвечают за два способа вывода в системе.
Если в модуле нет необходимости выполнять все перечисленные функции (как часто бывает), то соответствующие указатели устанавливаются в НУЛЛ.

Пример простого символьного драйвера; ядро 2.6.32. Достаточно функции read - драйвер будет производить работу только с устройством одного типа, можно создать глобальную структуру и заполнить её статически.

ssize_t read(struct file*, char*, size_t, loff_t*);
static struct file_operations simple_driver_fops = {.owner=THIS_MODULE, .read=devive_file_read}; //THIS_MODULE - макрос, объявленный в linux.h
static int device_file_major_number = 0;
static const char devicename[] = "simple_driver";
static int register_device(void)
{
	int result = 0;
	//объявлена в линукс/кернел.х; работает аналогично принтфу за исключением нюанса
	//стринговая константа имеет префикс KERN_чтото, который является приоритетом сообщения
	//может иметь восемь уровней: 0 KERN_EMERG (ядро нестабильно) .. 7 KERN_DEBUG (отладочная информация)
	//строка записывается в кольцевой буфер, из которого затем читается демоном klogd и записывается в /var/log/syslog и в kern/log
	//принтк написана так, что может быть вызвана из любого места ядра; однако кольцевой буфер может переполниться, из-за чего старые сообщения не появятся в сислоге
	printk(KERN_NOTICE"simple_driver:register_device()");
	result = register_chrdev(0, device_name, &simple_driver_fops)
	if (result < 0)
	{
		printk(KERN_WARNING"simple_driver:can't register with er.code=%i", result);
		return result;
	}
	device_file_major_number = result;
	printk(KERN_NOTICE"simple_driver:registered with major_num=%i", device_file_major_number);
	return 0;
}



04.04.15 ------------------------------------------------------------

Драйвер - ПО, управляющее работой устройства. Если рассматривать с точки близости к устройству, могут иметь многослойную иерархию. Виндус определяет драйверы-фильтры, позволяющие изменять функциональность; юникс - не настолько явно. Тем не менее, на основе загружаемых модулей можно создавать собстеные device-file, регистрировать их с помощью структуры file_operations, и с помощью определения своих функций - менять функциональность.

Продолжая предыдущий пример, рассмотрим функцию unregistration. Если мы зарегистрировали девайс-файл и его мажорный номер не равен нулю, то можно дерегистрировать этот файл устройства с помощью функции unregister_chrdev хедера <linux.h>
void unregister_device(void)
{
	printk(KERN_NOTICE "simple_driver unregister() call");
	if (device_file_major_number)
	{
		unregister_chrdev(device_file_major_number, device_name);
	}
}

В структуре file первый элемент - указатель на структуру модуля. Из неё мы получаем информацию: с каким файлом работаем, с какими защищенными данными связаны, и так далее. Второй параметр - буфер, выделенный в пространстве пользователя для чтения данных. 3 параметр - количество байт для чтения; 4 - смещение в файле. После выполнения функции read, указатель обновляется - функция должна вернуть количество успешно прочитанных байтов.
Наша функция рид ^ выполняет одно действие - копирует информацию в буфер (пространство пользователя) и печатает (пространство ядра). Пользователь не может просто переопределить указатель на адресное пространство режима беря указатель режима ядра. Система предоставляет специальный набор функций и макросов, объявленных в <asm/uaccess.h> . Для выполнения задачи функции рид, лучше всего подойдёт функция copy_to_user которая копирует данные из буфера в пространстве ядра в буфер в пространстве пользователя.
long copy_to_user(void_usr *to, const void *from, unsigned long n);

static const char hello[] = "Hello from Kernel \n\0";
static const ssize_t size = sizeof(hello);
static ssize_t dvice_file_read(struct file *file_ptr, char _user *user_buff, size_t count, loff_t *pos)
{
	printk(KERN_NOTICE "device file is read at offset=%i, read_byte count=%u", (int)*pos, (unsigned int)count);
	//если указатель в конце файла - ничего не прочтем
	if (*pos >= size )
		return 0;
	//при попытке прочитать больше записанного - читаем только то что есть
	if (*pos+count > size)
		count = size - *pos;
	if (copu_to_user(use_buff, hello + *pos, count) != 0)
		return EFAULT
	*pos += count;
	return count;
}
Используются библиотеки: linux/module.h, linux/kernel.h. При использовании дополнительных структур - соответствующие библиотеки. Если мы хотим расширить функциональность загружаемого модуля и включить в него обработчик прерываний, то соответственно включаем linux/interrupt.h. В linux/types.h раньше был определен тип dev_t - использовался для хранения номеров устройств; ныне kdev_t в linux/kdev_t.h.
Представляет собой 16битное число, в которое упакованы старший и младший номера устройства. В настоящее время потребность в младших номерах превышает 256 - изменить ёмкость dev_t нельзя, увы, старые прилоги поломаются. При этом пользовательским программам тип kdev_t недоступен. 
Функции ядра (может всётаки пользователя?) напрямую не должны использовать данный элементы данной структуры. Для работы с ней используются макроопределения и функции ядра.

MAJOR(kdev_t) - извлекает старший номер устройства
MINOR(kdev_t) - ну вы понили.
MKDEV(int ma, int mi) - создает структуру кдев_т из старшего и младшего номеров.
kdev_t_to_nr(kdev_t); - превращает в число типа dev_t
to_kdev_t(int dev); - число в структуру.


	Множество версий ядра.
Системные вызовы в разных версиях обычно остаются одними и теми же; новые могут добавляться, но старые не изменяются (по крайней мере в плане сигнатур) - обратная совместимость. В большинстве случаев также сохраняются и файлы устройств. При этом внутренний интерфейс в самом ядре может изменяться.

Версии ядра делятся на стабильные и развивающиеся.
stable (n.$<$ even number $>$.m)
development (n.$<$ odd number $>$.m)
Можно использовать директивы компиляции, в частности - сравнение макросов LINUX_VERSION_CODE, KERNEL_VERSION. Для версий ядра a.b.c значения определяются как $2^{16}a + 2^{8}b+c$

Пример:
#if LINUX_KERNEL_VERSION >= KERNEL_VERSION(2,2,0)
#define KERNEL_VERSION(a,b,c) ((a)*65536+(b)*256+c
#endif

В отличие от загружаемых модулей, драйверы должны иметь несколько точек входа. Точка входа - место, с которого начинает выполняться код; не только main() в случае драйвера.

	Структура драйвера.
struct driver
{
	int		(*probe)();		//интерфейс драйвера. Вызывается чтобы проверить, что контроллер присутствует.
	int		(*slave)();		//слейв-интерфейс драйвера. Вызывается один раз для каждого устройства, подключенного к контроллеру.
	int		(*cattach)();
	int		(*dattach)();
	int		(*go)();
	caddr_t	*addr_list;
	char	*dev_name;
	struct device **dev_list;
	char	*cttr_name;
	struct controller **cttr_list
	short	xclu;
	int		addr1_size;
	int		addr1_atype;
	int		addr2_size;
	int		addr2_atype;
	int		(*ctlr_unattach)();
	int		(*dev_unattach)();
};
Определяет точки входа и другую специфичную для драйвера информацию. Пользователь объявляет поля этой структуры в декларативной секции драйвера устройства.

//devdriver.h
	//struct driver банально копипаст ^
//none.c
	struct driver noned {noneprobe, 0, nonecatch, 0, 0 ... _name="none", ctlr_list=noneinfo} //устройство соединенное с контроллером отсутствует

Следующая специфичная для драйверов структура: device switch, переключатель устройства.
struct dsent
{
	int (*d_open)();
	int (*d_close)();
	int (*d_strategy)(); //относится к блочным устройствам.
	int (*d_read)();
	int (*d_write)();
	int (*d_ioctl)();
	int (*d_dump)();
	int (*d_psize)();
	int (*d_stop)();
	int (*d_reset)();
	int (*d_select)(); //заменяет poll из старых линуксов
	int (*d_mmap)(); //может использоваться при работе с памятью как с внешним устройством
	int (*d_segmap)(); //-''-
	struct tty *d_ttys;
	int d_funnel;
	int d_bflags;
	int d_cflags;
};
Структура переключателя содержит точки входа драйвера устройства и другую информацию, специфичную для символьных и блочных устройств. Драйвер устройства объявляет экземпляр и задает соответствующие значения полям структуры dsent. Драйвер регистрирует информацию, содержащуюся в структуре, и резервирует соответствующий старший номер, путем вызова интерфейса devsw_add().
Ядро поддерживает таблицу структур dsent, каждая структура соответствует старшему номеру.

(диаграмма 1)

Относительно raw, сырых устройств. Raw device - устройства, в которых данные передаются потоками байтов разного размера. Могут получать как один байт, так и многие мегабайты (гигабайты) за одну передачу.
Есть блочные устройства с разными интерфейсами. В современных системах все блочные устройства поддерживают байт-ориентированный доступ в "прозрачном" (raw) режиме. Для них предусмотрены соответствующие байт-ориентированные специальные файлы - они обеспечивают символьный доступ к устройствам с блочной структурой в случае необходимости. Имена таких файлов имеют префикс r_ или располагаются в отдельном каталоге /dev/rdsk

Добавление входов в таблицу загружаемых драйверов. Описанные действия должны находиться в тексте драйвера.
//none.c
struct dsent none_devsw_entry = {noneopen, noneclose, nodev, noneread, nonewrite, noneioctl, nodev, nodev, nodev, nodev, nodev, 0,0,NULL, DEV_FUNNEL, 0, 0};
int majnum = devsw_add(mcfgname, MAJOR_INSTANCE, -1, &none_devsw_entry); //имя драйвера, int константа, старший номер который разработчик резервирует, адрес заполненной структуры. -1 - девсв_адд сама получит старший номер

//ondisk device switch table
struct dsent cdevsw[MAX_DEVSW]=
{
	{cnopen, ...}, //0
	...
	{dtlopen,...}, //25
	...
	{noneopen, noneclose,nodev,...,0,0} //26 //имеет мажорномер majnum
};
девсв_адд берет адрес заполненной структуры; в ^ демонстрируется как сервис вводавывода связан с нашим "драйвером" (щито блеать?)

(диаграмма 2)

Стратегия определяет стратегию блок-ориентированного ввода-вывода.



	Блочные устройства.
Они же блок-ориентированные специальные файлы. Представители - диски.
(*картинка хдда с пластинами-дисками, дорожками, секторами, кареткой, магнитными головками*)
Сектора имеют разные размеры внешние больше внутренних. Дорожки нумеруются 0..Н снаружи-внутрь. Совокупность дорожек, имеющих один номер, называется цилиндром. Блок - ... . Перемещение каретки до сответствующей дорожки - время поиска цилиндра. Поворот дисков до соответствующего сектора - время ожидания записи. Размер сектора определяет время передачи.

В мультипроцессных системах большое количество процессов могут нуждаться в операциях ввода-вывода на диск. К устройству будет организована очередь запросов - для оптимизации во времени обслуживания процессов, которые нуждаются в поиске, записи и так далее на диске. Запросы можно упорядочить разными способами; в основу кладется стратегия планирования поиска. Оная должна учитывать следующие параметры: пропускная способность, среднее время ответа, дисперсия времен ответа (предсказуемость времен ответа - тем выше чем меньше дисперсия).
Стратегии планирования должны минимизировать время на поиск записи и повышать пропускную способность процесса обслуживания запросов.

1.FCFS. Очередь запросов: 4 3 2 1
Сектора на диске: * 2 4 _ 3 1  <- каретка
Каретка перемещается к 1, затем к 2 ну и такдалее. Путь долгий, каретка мечется туда сюда - можно выполнять по другому.
2.ShortestSeekTimeFirst. Возможно бесконечное откладывание
3.SCAN - каретка перемещается в одном направлении, пока в этом направлении есть запросы. Как не осталось запросов - направление меняется. Время ожидания для крайних дорожек может значительно превышать среднее время доступа.
4.C_SCAN - circle scanning, каретка движется в одном направлении от внешней к внутренней дорожки. Если впереди больше нет запросов, то каретка скачком возвращается на внешнюю дорожку, ближайшую к началу, к которой есть запрос.
5.N_step_SCAN - н-шаговое сканирование. Каретка движется туда-обратно; все запросы во время движения в одном направлении группируются так, чтобы их наиболее эффективно обслужить во время обратного хода.
6.Схема_Эшенбаха - каретка движется циклически как в 4. Предусматривается упорядочение запросов в рамках одного цилиндра, которое учитывает угловое положение записей.
В результате выяснилось, что стратегия кругового сканирования с оптимизацией поиска в зависимости от нагрузки является наиболее эффективной. При наличии нескольких запросов к одной дорожке, они упорядочиваются таким образом, чтобы их можно было обслужить за один оборот диска.

	Создание и регистрация блочных устройств в системе.
Любое блочное устройство - устройство хранения с произвольным доступом. Для блочных устройств значимыми являются два фактора: 1.производительность сиречь скорость - одно из конкурентных преимуществ ОС на рынке. 2.получение запросов вводавывода как от пользовательских приложений, так и от кода ядра.
Блок данных - единица данных фиксированного размера; размер определяется ядром, чаще всего совпадает с размером страницы (в архитектуре х86 - 4096 байт).
Диски делятся на сектора - исторически сложилось так, что аппаратное обеспечение создавалось для работы с секторами 512 байт. В последнее время появилась тенденция увеличения размера сектора до 4096 байт.

Для регистрации используется специфический API.
int register_blkdev(unsigned major, const char *name);
void unregister_blkdev(unsigned major, const char *name);
Аналогично символьным, в качестве старшего номера может передано специфическое значение. Если устройство с таким старшим номером уже зарегистрировано, будет возвращена ошибка; можно передавать 0 - тогда старший номер будет присвоен динамически.
Регистрация имени устройства создает соответствующую запись в файле /proc/devices .



18.04.15 ------------------------------------------------------------

Если создаются диски xda, xdb, то "родовым именем класса" будет xd. Регистрация имени устройства создает соответствующую запись в файле /proc/devices; не создает самого устройства в /dev. Начиная с ядра 2.6 регистрация с помощью ^ необязательна, "дань традиции".
Для каждого устройства должна быть создана очередь обслуживания. Она должна использоваться монопольно: использование выполняется в режиме взаимоисключения. Для этого используется спинлок.

Очередь обслуживания создается с помощью xda_request_queue = blk_init_queue(&xda_request_func, &xda_lock). Этот вызов создает очередь обслуживания запросов в ядре и связывает её с примитивом хда_лок. Этот примитив синхронизации в дальнейшем используется при реализации взаимоисключений. Кроме примитива передается также функция обработки запросов - будет вызвана ядром при каждом запросе на чтение или запись, обращенные к диску. Прототип: static void xda_request_func(struct request_queue &p);
Обработка запросов с помощью очереди ядра - не единственный способ обеспечения операций ввода-вывода, но такой способ используют 95% драйверов. Остальные работают напрямую с запросами по мере их поступления.
Для отображения бллочного устройства в каталог /дев необходимо создать для устройства struct gendisk; описана в <linux/genhd.h> . Эта структура описывает каждый диск в ядре. Затем заполняются поля структуры.
Экземпляром этой структуры также описывается каждый раздел диска (partition).
gendisk - динамически создаваемая структура; для создания и уничтожения используются системные вызовы gendisk* alloc_disk(int minors); void del_gendisk(struct gendisk*); минорс - указывает число младших номеров, используемых для отображения диска и его разделов в каталоге /dev.

	Прерывания (аппаратные)
Естественный асинхронный параллелизм. Общая модель обработки является принципиально архитектурно-зависимой.
ДОС: контроллер прерываний PIC; адрес прерывания в досе - 4байтовый вектор в таблице дескрипторов прерываний.
32разрядные системы: расширенный контроллер APIC. Доступ к обработчику прерываний осуществляется через 8байтовый дескриптор прерываний / шлюз (gate), который находится в IDT таблице дескрипторов. В многоядерной системе каждый процессор будет работать с собственной ИДТ.
Прерывания выполняются на высшем уровне приоритета относительно других действий. Когда выполняется обработчик прерывания, прервать его может только более высокоприоритетное прерывание.

Аппаратные прерывания делят на два типа: быстрые и медленные (short, long).
Быстрые - interrupt service route должна быть очень короткой и прерывать текущую активность ненадолго.
Одна из характеристик быстрых прерыванй - все другие прерывания на локальном процессоре блокируются во время их выполнения. Обработка быстрых прерываний не может быть прервана - нет "вложения" прерываний; более приоритетные прерывания не прерывают выполнение менее. Речь идёт ТОЛЬКО О БЫСТРЫХ прерываниях!
Быстрые прерывания получают или отправляют данные на последующую обработку.
Особняком стоит обработчик прерываний системного таймера. Его функции диктуются многопроцессностью, квантованием времени.

Медленные прерывания - могут выполняться в течение какого-то промежутка времени и могут быть прерваны другими прерываниями. В никсах для реализации этих двух типов прерываний вводится понятие top-half и bottom-half. Таким образом прерывание делится на быструю топ и медленную боттом части (картинка запросов на ввод-вывод из Шоу - вызов супервизора и так далее с прошлого семестра).

Цикл запросов на ввод-вывод.
*диаграмма1*

Прерывание "входит в состав" драйвера. Каждое устройство имеет один связанный с ним драйвер; если оно использует прерывания, то драйвер регистрирует обработчик прерывания. Драйверы могут регистрировать обработчики прерывания с помощью следующей функции:
int request_ireq(unsigned int irq, irqreturn_t (*handler)(int, void*, struct pt_regs*), unsigned long irqflags, const char* devname, void *dev_id);
1параметр: номер прерывания. Для части обычных устройств эти номера зафиксированы "аппаратно" (вхардкожены). Таймер, клавиатура и т.п. Для большинства других устройств номера irq "зондируются" или определяются программой динамически.
2параметр: указатель на функцию обработчика прерывания, которая обслуживает прерывание. С помощью реквеста мы можем зарегистрировать в системе собственный обработчик прерывания для данного девайса. Данный обработчик будет вызываться системой при возникновении прерывания с определенным номером.
3параметр: флаги. 0 или битовая маска следующих флагов:
	SA_INTERRUPT - обработчик будет отвечать быстрому прерыванию; остальные прерывания будут запрещены. Используется если хендлер не должен затормозиться ничем.
	SA_SAMPLE_RANDOM "определяет что данное прерывание должно вносить вклад в пул энтропии", что бы это ни значило (видимо как-то связано с генерацией случайных чисел в ядре). Не устанавливается для устройтв, генерирующих прерывания с определенной частотой.
	SA_SHIRQ - указывает что линия прерывания может разделяться между множеством обработчиков прерываний.
4параметр: аски-текст, показывает устройство, связанное с прерыванием. "keyboard" и так далее. Будет использоваться в /proc/irq, /proc/interrupts
5параметр: идентификатор устройства, которое вызывает прерывание по данной линии; используется в основном вместе с флагом SA_SHIRQ

Исключая прерывание от таймера, большинство прерываний не устанавливают флаг СА_ИНТЕРРУПТ.



25.04.15 ------------------------------------------------------------

^ второй параметр, обработчик.
static irqreturn_t intr_handler(int irq, void *dev_id, struct pt_regs *regs);
Никогда не вызывается непосредственно из другого файла; должен быть определен как static. Возвращает одно из двух предопределенных значения: IRQ_NONE, IRQ_HANDLER. Первое возвращается, если обработчик обнаруживает прерывание, которое его устройство не порождало; второе - если обработчик прерывания был корректно вызван и его устройство сформировало прерывание.
- irq - числовое значение линии прерываний, которую обслуживает обработчик. В настоящее время не используется, разве что в логах записи.
- дев_ид - общий указатель (common pointer) на тот же дев_ид что задается в реквест_ирй, регистрируемый обрабботчиком прерываний. Если это значение уникально - оно используется для выполнения "различий" между множеством устройств, которые потенциально могут использовать один обработчик прерывания. Также может указывать на структуру struct device, используемую обработчиком прерываний; девайс используется внутри обработчика и является уникальным для каждого устройства.
- regs - указатель на структуру с регистрами процессора; используется в основном в отладочных целях.

Все прерывания описываются в коде драйвера и является одной из точек входа, если устройство генерирует прерывания. Так как драйвер работает с устройством (конкретным), то в системе оно представляется структурой struct device - для каждого устройства она уникальна и описывает его особенности.

	Верхние и нижние половины (top, bottom half) (см. выше)
После инициирования прерывания процедуры обработки должны выполняться как можно быстрее - все аппаратные прерывания выполняются на самых высоких уровнях привелегий (прерывают всю выполняемую в системе работу). Тем не менее, не все задачи можно выполнить за несколько инструкций. Так, обработчик поступившего в сетевой адаптер пакета требует несколько тысяч тактов, прежде чем пакет может быть передан в соответствующее адресное пространство режима пользователя (процессу, запросившему пакет). Задача формируется прерыванием, но не может быть выполнена (быстро) его обработчиком.

Чтобы максимально сократить время обработки, такие трудоемкие задачи делятся на две части, верхнюю и нижнюю.
Верхняя половина top half запускается после срабатывания прерывания (функции обработчика верхней половины передается управление при возникновении прерывания). Функция обработчика верхней половины выполняется при запрещенных прерываниях.
//в настоящее время для этого используется набор API специфичный для SMP - Symmetric MultiProcessing. В результате можно или запретить прерывания по всем линиям IRQ локального процессора, или на всех процессорах можно запретить конкретную линию ИРЙ. Макросы управления: <linux/irqflags.> void local_irq_disable()/_enable() ; int irq_disable (проверка) вернет ненулевое значение, если прерывания были запрещены на локальном процессоре. void disable_irq/enable_irq(unsigned irq). void syncronize_irq(unsigned irq) - ожидает, пока завершится обработчик, установленный на линии irq, если тот выполняется.
Обработчик верхней половины завершается традиционным ретурном. Например, процедура обработки прерывания от сетевого адаптера может просто копировать приходящий пакет в ядро. В ядре такой пакет ставится в буферную очередь, в которой ожидает непосредственной обработки соответствующим потоком. Обработчик верхней половины активизирует последующее выполнение нижней половины, которое позже завершит начатую работу.

Таким образом, обработчик верхней половины должен зарегистрировать в системе отложенное прерывание. После возврата верхней половины ядро завершает взаимодействие с аппаратурой контроллера прерываний, разрешая прерывания, восстанавливая маску прерываний контроллера, и возвращает управление из прерывания уже именно командой IRET.

Нижняя половина bottom half запускает все операции, для которых время не является критическим фактором, а выполняемые действия требуют слишком много процессорного времени. По окончанию работы обработчика верхней половниы, вызывается планировщик, который скорее всего запустит на выполнение нижнюю половину этого же прерывания. Нижняя половина выполняется при разрешенных прерываниях.
Исторически в линуксе сменилось несколько API реализаций данной схемы. Все новые схемы построены на выполнении обработчика нижней половины отдельным потоком ядра. В настоящее время используются несколько механизмов: softirq, tasklet, workqueue (очереди отложенных действий). Между тасклетами и софтирк есть важные отличия.

	Запуск отложенных прерываний SoftIRQ.
Перед запуском зарегистрированного отложенного прерывания, оно должно быть поставлено в очередь на выполнение, "промаркировано". Этот процесс называется генерацией отложенного прерывания - raise softirq. Как правило, маркировка для их последующего запуска выполняется перед возвратом из обработчика прерываний.
Перед своим завершением, обработчик должен вызвать функцию raise_softirq(***_SOFT_IRQ); return IRQ_HANDLER.

К примеру, если вызвать райз с NET_SOFTIRQ, будет сгенерировано прерывание с таким индексом. Соответствующий обработчик будет запущен в подходящее время.
Определяют следующие инедксы отложенных прерываний со следующими приоритетами:
HI_SOFTIRQ		0	высокоприоритетные тасклеты
TIMER_SOFTIRQ	1	таймеры
NET_TX_SOFTIRQ	2	отправка сетевых пакетов
NET_RX_SOFTIRQ	3	прием сетевых пакетов
BLOCK_SOFTIRQ	4	блочные устройства
TASKLET_SOFTIRQ	5	тасклеты с обычным приоритетом
SCHED_SOFTIRQ	6	планировщик
HRTIMER_SOFTIRQ	7	высокоточные таймеры
RCU_SOFTIRQ		8	RCU-блокировка

Проверка ожидающих выполнения обработчиков прерываний и их запуск осуществляется в следующих случаях:
* при возврате из обработчика аппаратного прерывания
* в контексте потока ядра вызывается демон ksoftirqd
* в любом коде ядра, где явно проверяются и запускаются ожидающие обработчики (например в сетевой подсистеме)
Независимо от метода вызова отложенного прерывания, его выполнение осуществляется путем вызова функции _do_softirq(). Оно в свою очередь вызывается из функции do_softirq(). Если в системе есть ожидающие выполнения отложенные обработчики, то функция проверяет их все и вызывает соответствующие обработчики.

Для регистрации обработчиков отложенных прерываний используется функция open_softirq(индекс отложенного прерывания, функция-обработчик, данные). open_softirq(NET_TX_SOFTIRQ, net_tx_action, NULL);

	Тасклеты.
Частный случай реализации SOFTIRQ - базируются на оном, но являются отложенными прерываниями, для которых обработчик данного прерывания не может одновременно выполняться на нескольких процессорах. Имеют более простой интерфейс и упрощенные правила блокировок. В отличие от тасклетов, софтирй одного типа (прерывания) могут выполняться одновременно, что влечет за собой реализацию блокировок в теле софтирй.
На разных процессорах могут выполняться только тасклеты разных типов. SOFTIRQ зарегистрированы статически и могут быть лишь определенных типов; тасклеты же можно регистрировать динамически.

Инициализация тасклетов.
Статически, тасклеты создаются с помощью двух макросов из <linux/interrupts.h>: DECLARE_TASKLET(name, func, data); DECLARE_TASKLET_DISABLED(name, func, data). Оба макроса статически создают экземпляр структуры struct tasklet_struct с именем name, вызываемой функцией функ, которой передаются данные дата.
{
	tasklet_struct *next;
	unsigned long state;
	atomic_t count; //счетчик ссылок
	void (*func)(unsigned long); //обработчик
	unsigned long data;
};
Первый макрос создает тасклет, у которого каунт=0; тасклет "разрешен".

При динамическом создании тасклетов объявляется указатель на структуру struct tasklet. Для его инициализации вызывается функция tasklet_init(). Затем тасклет должен быть запланирован с помощью одной из двух функций: tasklet_schedule(tasklet_struct*), tasklet_hi_schedule(tasklet_struct*). Запланированные на выполнение хранятся в двух связных списках: tasklet_vec (обычные) и tasklet_hi_vec (высокоприоритетные). Оба связных списка состоят из отдельных тасклетов, которые фактически определяются как экземпляры структуры tasklet_struct.
После планирования тасклет будет запущен только единожды, даже если был запланирован несколько раз. Для отключения заданного тасклета используется функция tasklet_disable() или tasklet_disable_nosync(). Первая не сможет отменить тасклет, который уже выполняется; вторая может прерывать работу выполняющегося тасклета.



16.05.15 ------------------------------------------------------------

При выполнении нижних половин прерывания разрешены; их обработчики бывают трех видов, мы рассматриваем тасклеты и softIRQ. SoftIRQ - определены статически, тасклеты - строятся на их основе.

Поскольку один тасклет не может выполняться параллельно на нескольких процессорах, требования к взаимоисключениям более простые.
Если есть ограничение по времени выполнения - лучше использовать softIRQ. В то же время техника реализация тасклетов более простая; могут быть созданы статически (используют макросы) и динамически (объявляют указатель на структуру тасклета и вызывают tasklet_init()).

tasklet_init(task /*указатель*/, tasklet_handler, data);
При инициализации тасклета инициализируется хендлер, имеющий вид:
void tasklet_handler(unsigned long data);
Замечание: в обработчиках тасклетов нельзя использовать семафоры, так как тасклеты не могут переходить в состояние блокировки. Это чревато дедлоком внутри ядра.

Как было сказано в прошлом семестре, в процессорах существует команда test_and_set, которая используется втом числе в спинлоках в обработчиках нижних половин.


	Обслуживание прерываний в Windows
Устройство ввода-вывода генерирует прерывание по завершении операции этого ввода-вывода. При этом, в результате формирования вектора прерывания (в х86) с использованием message signal interrupt будет передано управление соответствующему обработчику прерываний. В виндах это называется "обработчик ловушки".
В х86 по таблице IDT находится адрес interrupt service routine. В виндах 2000+, ISR обычно обрабатывают прерывания в два этапа. На первом этапе вызывается ISR, которая выполняется на уровне device_IRQL (таблица уровней прерываний из прошлого семестра), высоком уровне привелегий. Эти действия должны выполняться очень быстро, по аналогии с линуксовыми половинами.
После этого  ISR помещает отложенный вызов DPC (deferred procedure call) в очередь. Затем, когда очередь доходит до данного отложенного вызова, процедура драйвера устройства выполняет завершение обработки прерывания. После чего драйвер вызывает диспетчер ввода-вывода, который завершит ввод-вывод и удалит ISR из очереди.

(диаграмма 1)
(диаграмма 2)
Картинки также присутствуют в соломоне-русиновиче.

DPC-процедура выполняет основную работу по обработке прерывания, которая остается после завершения ISR. При этом работа выполняется на уровне DPC_dispatch, что позволяет не блокировать другие аппаратные прерывания.
ISR должна выполнять минимум действий по обслуживанию устройства, а именно:
1.сохранять информацию о состоянии прерывания. Информация из регистра данных контроллера в системном буфере (аналогично никсовому top-half).
2.отложить передачу данных и выполнение других некритичных по времени операций до снижения IRQL до DPC_dispatch (как bottom-half, завершает обработку прерывания).

DPC таймер.
DPC процедура выполняется по истечению кванта. При каждом такте системного таймера вызывается прерывание IRQL_clock. Обработчик прерывания уменьшает счетчик кванта. Когда тот обнуляется (квант заканчивается), ядру может понадобиться перераспределить процессорное время.
Задача перераспределения имеет более низкий приоритет DPC_dispatch. Обработчик прерывания таймера ставит ДПЦ в очередь, чтобы инициализировать диспетчеризацию потоков, после чего завершает работу и понижает ирйл процессора.
Поскольку диспатч имеет приоритет ниже всех аппаратных прерываний, то вначале обрабатываются они, а затем прерывание дпц.


	Сокеты
Средство взаимодействия процессов, но основная идея - взаимодействие в сетях.
Были созданы для организации взаимодействия процессов, причем безразлично где те работают - на одной машине или на разных. Абстракция сокетов была введена в BSD Unix, поэтому их часто называют БСД-сокетами или сокетами Беркли (Berkley Software Distribution).
Сокет представляет собой абстракцию конечной точки взаимодействия. В результате приложение может использовать единообразный интерфейс сокетов для отправки и получения данных (формируемых в виде сообщений) как по сети так и на локальной машине, с использованием различных протоколов.
Нужные протоколы выбираются на основе определенных значений трех параметров:
1.семейство (family).
2.тип (type).
3.протокол (protocol).

(диаграмма 3)
(диаграмма 4)

Разделяют три вида сокета - датаграммные, raw, stream.
Сокет реализуется в системе "многослойно". В системе это адрес (порта), с которым связан системный буфер (получаемое сообщение копируется в него), из которого информация копируется в адресное пространство процессора. Данное справедливо для любого типа сокета.
Netlink сокеты - позволяют приложениям получать доступ к информации ядра, причем на уровне пользователя.

Ядро линукса предоставляет для работы с сокетами один единственный системный вызов. Используется системный вызов копирования из юзерспейса
net/socket.c
asmlinkage long sys_socketcall(int call, unsigned long *args)
{	. . .
	if copy_from_user(a, args, nargs[call])
		return -EFAULT
	a0 = a[0];
	a1 = a[1];
	switch( call )
	{
	case SYS_SOCKET:
		err = sys_socket(a0, a1, a[2]);
		break;
	case SYS_BIND:
		err = sys_bind(a0, (struct sockaddr*)a1, a[2]);
		break;
	case SYS_CONNECT:
		...
	default:
		err = -EINVAL;
	}
	return err;
}
Фактически данный системный вызов представляет просто переключатель. Параметр call определяет номер нужной функции. В ядре 2.6.28 всего определены 18 возможных констант и функций.
Приложение вызывает функцию socket:
#include <sys/types.h>
#include <sys/sockets.h>
int socket(int domain, int type, int protocol);
В результате такого вызова происходит вызов sys_socket из <net/socket.h>. Внутри той функции объявляется указатель на struct socket и вызывается int retval = sock_create(family, type, protocol, &sock). Ретвал - файловый дескриптор сокета, возвращаемый пользовательской функцией socket(). Да, сокет в системе тоже открытый файл.
Дизайн сокетов беркли следует парадигме юникс - в идеале, отобразить все объекты, к которым осуществляется доступ для чтения-записи, на файлы. Чтобы с ними можно было работать путем обычных операций записи и чтения из файла.

struct socket
{
	socket_state		state;	//определяет одно из пяти состояний
	short				type; //хранит второй параметр socket(_, type)
	unsigned long		flags; //используется для синхронизации доступа
	const struct proto_ops	*ops; //ссылается на действия подключенного протокола
	struct fasync_struct	*fasync_list; //список асинхронного запуска
	struct file			*file;
	struct sock			*sk;
	wait_queue_head_t	wait;
};
Сокет может находиться в пяти состояниях: SS_FREE - незанят; SS_UNCONNECTED - не соединен; SS_CONNECTING - соединяется в данный момент; SS_CONNECTED - соединен; SS_DISCONNECTING - разъединяется.
Допустимые значения второго параметра socket() определены в файле include/asm/socket.h: SOCK_STREAM, SOCK_DGRAM, SOCK_RAW, SOCK_RDM, SOCK_SEQPACKET, SOCK_PACKET. Последний не следует больше использовать.
Сокет в никсах является специальным файлом, в $ ls отображается символом s, поэтому структура сокета содержит указатель на структуру файла, а та ссылается на inode.

Адреса сокетов.
Сокеты БСД поддерживают множество протоколов, поэтому была определена общая структура адреса sockaddr.
struct sockaddr
{
	unsigned short	sa_family;
	char			sa_data[14];
};
Имеет очень общий вид - сделано намеренно, но пользоваться неудобно, поскольку не определен точный формат адреса.
При этом содержимое поля sa_data по-разному интерпретируется в зависимости от значения sa_family, которое определяет идентификатор семейства (домена). Поскольку напрямую работать с sa_data напряженно, можно использовать одну из двух структур: struct sockaddr_in (internet), struct sockaddr_un (unix).
struct sockaddr_in
{
	short 			sin_family;
	unsigned short	sin_port;
	struct in_addr	sin_addr; //IP-address
	unsigned char	sin_zero[8];
};
При этом при заполнении этой структуры, адреса и номера портов должны быть указаны в сетевом порядке байтов.

Операции сокетов.
В прикладном интерфейсы сокеты представляются дескрипторами файлов.
Эти дескрипторы могут использоваться для выполнения операций записи и чтения, однако установка коммуникационных отношений существенно отличается от открытия файла. С точки зрения приложения, для сокетов доступны специальные системные вызовы.
Взаимодействие через сокеты реализуется по модели клиент-сервер, причем при взаимодействии роли клиента и сервера отличаются с точки зрения коммуникационных отношений. Клиент инициирует установление контакта, а сервер сначала остается пассивным, ожидая входящих запросов на установление контакта.



23.05.15 ------------------------------------------------------------

Действия на стороне клиента и сервера разнятся вместе с ролями.
(диаграмма1)

Два значимых протокола - TCP и UDP. Для протоколов, не требующих установления соединения (УДП) на стороне клиента не нужен бинд и коннект, а на стороне сервера - листен и акцепт.

bind() используется для присвоения сокету локального адреса. Для сокетов интернета этот адрес: ip, port. Клиенты могут действовать без этого вызова, так как их точный адрес часто не играет роли. В таком случае адрес назначается им автоматически.
listen() используется сервером для информирования операционной системы о том что на данном сокете нужно принять соединение. Имеет смысл только для протоколов, ориентированных на соединения (только TCP в настоящее время).
connect() устанавливает соединение по переданному адресу. Для протоколов без установления соединения может использоваться для указания адреса назначения для всех передаваемых впоследствии пакетов.
accept() используется сервером для принятия соединения при условии, что он ранее получил запрос соединения. В противном случае вызов будет заблокирован до тех пор, пока не поступит запрос на соединение.

Когда соединение принимается, сокет _копируется_ - первоначальный сокет остаётся в состоянии listen, а новый в состоянии connect. Вызовом акцепт возвраается новый дскриптор файла для второго сокета. Такое дублирование в ходе принятия соединения даёт серверу возможность принимать новые соединения без необходимости предварительно закрывать предыдущие соединения.

Современные системы освобождают программистов от многих рутинных действий. Локальная машина предоставляет транспортные механизмы передачи; используется буфер для хранения сообщений и адрес оного буфера.
Прежде чем тсп-клиент и сервер смогут передать сообщение друг другу, каждый должен определить (specify) пару сокетов для соединения: локальный айпи-адрес, локальный порт; чужой айпи, чужожй порт.


	Модели ввода-вывода
В юниксоподобных системах доступны пять моделей ВВ.
1.Блокирующий ВВ.
(диаграмма2).
recvfom() вызывается из приложения и работает в режиме пользователя. Затем выполняется переключение в режим ядра. В результате вызова рецвфром процесс блокируется до тех пор, пока не поступят данные и системный вызов не запишет их в буфер приложения. Пока процесс блокирован в ожидании данных, он не отвечает на запросы, причем время блокировки зависит от качества связи.

2.Неблокирующий ВВ (polling).
(диаграмма3)
При работе с сокетами может быть установлен неблокирующий режим. recvfrom() вызывается в цикле до тех пор, пока ядро не вернет данные для считывания. На схеме показывается, что первые вызовы результат не возвращают, так как ядро "видит", что данных нет, и возвращает ошибку EWOULDBLOCK. Наконец сисвызов выполняется успешно - ядро записывает аднные в буфер процесса и они становятся доступны для обработки. Данный способ связан с большими накладными расходами, так как система не может перейти к другой эффективной работе и вынуждена выполнять опрос.

3.Мультиплексирование
(диаграмма4)
Модель связана именно с сокетами и отсутствует вне сетевого взаимодействия. Для реализации можно использовать один из доступных системных вызовов мультиплексеров: select, poll, pselect, epoll (рекомендован для линукса). Преимущества мультиплексированного ВВ перед блокируемым в том, что эта модель позволяет обрабатывать не один а несколько дескрипторов. После получения статуса readable данные можно получать с помощью соответствующих системных вызовов (recvfrom), которые также блокируют процесс. При этом мультиплексор уменьшает время блокировки: готовность данных на любом сокете из пула вероятнее чем готовность данных на конкретном.
В данном случае, в цикле проверяются все сокеты; их количество устанавливается в приложении, затем берётся первый готовый. Пока обрабатывается первый готовый сокет, могут стать готовыми другие - в результате снижается время блокировки.

4.Signal-driven ВВ
(диаграмма5)
Когда дескриптор готов к считыванию, ядро должно послать сигнал SIGIO. Последовательность действий: установить параметры сокета для работы с сигналами; установить обработчик сигнала сисвызовом sigaction. Приложение не блокируется, работу берет на себя ядро, отслеживая готовность данных и посылая сигнал SIGIO. Сам вызов recvfrom() не приведёт к длительной блокировке, поскольку данные уже готовы; вызов можно производить как в обработчике сигнала, так и в основном потоке программы. Сигнал типа SIGIO для каждого процесса может быть только один - в результате, за один раз можно работать только с одним файловым дескриптором.

5.Асинхронный ВВ.
(диаграмма6)
Прямого отношения к сокетам не имеет. функции имеют приставку aio_ или lio_. В aio_read передаётся дескриптор, адрес буфера, размер буфера (как в обычный read()), а также указатель на файл и "способ" сообщения о завершении операции. Результат вызова происходит немедленно; процесс, вызвавший асинхронный запрос ВВ, не блокируется пока ждёт завершения ввода-вывода.
В примере на диаграмме авторы предполагают, что ядро генерирует некоторый сигнал, когда операция завершается, причем этот сигнал не генерируется пока данные копируются в буфер приложения.
Проблема - асинхронные сообщения нужно получать синхронно. Внимание заостряется на определении, что ВВ можно выполнить быстро, и на том вызов возвращает результат немедленно (в противном случае возвращается ошибка).

В первых четырех моделях, первая фаза (ожидание данных) выполняется по-разному, а вторая (копирование из ядра) одинаково - блокирование на системном вызове recvfrom(). В асинхронном ВВ диаграмма описывает обе фазы разом; ни в одной из них процесс не блокирован.

POSIX определяет два термина (синхронный и асинхронный ВВ) следующим образом. Синхронные операции ВВ - требуют, чтобы процесс был блокирован до завершения операции ВВ. Асинхронный ВВ - не вызывает блокирования процесса. С использованием этого определения, первые четыре модели ВВ - синхронные, поскольку операция ВВ блокирует процесс, даже в случае управления сигналами.


	Синхронизация и взаимоисключения в ядре
Если несколько процессов обращаются к одним и тем же структурам и пытаются что-то изменить, то возникают проблемы, которые могут привести к нежелательным последствиям. Пример: два параллельных процесса пытаются добавить в односвязный список типа очередь новый элемент.
struct queue
{
	int data;
	struct queue *next;
};

struct queue *q;
q = new(queue);
q->data = 0;
q->next = NULL;

p1:					p2:
struct queue *a;	struct queue *b;
a = new(queue);		b = new(queue);
a->data=1;			a->data=2;
a->next = q->next;	b->next = q->next;
q->next = a;		q->next = b;

Процессы пытаются записать новый элемент в очередь. Первый доходит до a->next = q->next; выполняет и прерывается. Выполняется второй, также выполняет b->next = q->next; q->next = b; прерывается. Возобновляется первый, q->next = a; - информация о b потеряна.
Для ядра характерна работа со списками. Работа с разделяемыми структурами должна выполняться в режиме монопольного доступа.

Основные средства взаимоисключения в ядре - спинлоки, основанные на ряде машинных команд test_and_set. Также в ядре могут использоваться семафоры. Сама команда как правило выполняет действия над одним битом.
Линукс использует следующие команды: test_and_set_bit(nr, void* addr) - устанавливает 1 по адресу addr в бит с указанным номером; возвращает предыдущее значение этого бита. Если два потока пытаются одновременно произвести действие над одним и тем же битом, то свойство атомарности этой операции, даст возможность сделать это потокам только последовательно. Прервать выполнение этого действия не может даже прерывание; если оно возникает, то будет обработано после разрешения команды (см прошлый семестр, цикл выполнения команды - наличие сигнала прерывания проверяется в конце цикла).
Как правило 1 символизирует о "ресурс занят". Освобождение ресурса происходит сбросом бита в ноль: test_and_clear_bit(nr, void* addr).

В никсах определены атомарные операции над целыми числами. Используется тип atomic_t, эквивалентный int.
atomic_set(atomic_t *var, int i) устанавливает значение переменной в i. atomic_read(), _inc, _dec, и так далее.
Атомарные операции используются для изменения одного значения. Часто критические секции невозможно сократить до одной команды - необходимо использовать спин-блокировки.

Спин-блокировка - в линуксе реализуются посредством переменной типа spinlock_t, соответствующей инту. Для работы со спинлоками существует набор функций:
spin_lock(spinlock_t *ms) захватывает критический участок
spin_unlock(...) освобождает участок.
spin_lock_irqsave(spinlock_t *ms, unsigned long flags) блокирует участок и дополнительно предотвращает возникновение прерываний. Сохраняет регистр состояния процессора в переменную флагов.
spin_lock_irqrestore(...) освобождает участок и разрешает прерывания обратно.
Также есть блокировки, запрещающие вызов нижних половин.

Спин-блокировки связаны с активным ожиданием, но при этом (особенно в ядре) они не могут долго занимать процессорное время. Корректная реализация спин-блокировки выглядит следующим образом:
void spin_lock(spinlock_t *s)
{
	while (test_and_set(s) != 0)
		while (*s != 0);
}
Вводится дополнительный цикл, в котором выполняется непосредственно проверка переменной. При этом внутренняя проверка не блокирует шину памяти.
Процессор расходует процессорное время, ожидая освобождения ресурса. Альтернативой спинлокам являются средства взаимо-исключения, переводящие процесс в состояние блокировки. В этом случае процессор может начать выполнение другой работы, но такая реакция системы также характерна издержками: два переключения контекста - один для перехода к другой задаче, второй для выполнения к прерванной при освобождении ресурса и выхода из блокировки. Переключение контекста требует довольно большого объёма кода, который значительно больше того, что потребовал взаимоисключения.
Разумно использовать спин-блокировку в тех случаях, если время её удержания меньше времени двух переключений. Такая оценка затруднительна - разработчики ПО просто должны учитывать факт активного ожидания и удерживать блокировки по возможности в течение максимально короткого времени. Необходимо обеспечивать монопольный доступ к данным и не исключать выполнения строк кода.

В линуксе спин-блокировки нерекурсивны - это может привести к самоблокировке - если поток входит в цикл ожидания освобождения блокировки, которую сам же и удерживает.
Спинлоки могут использоваться в обработчиках прерываний (семафоры - не могут, поскольку переводят процесс в состояние блокировки). Если блокировка используется в обработчике прерывания, то перед тем как его захватить, необходимо запретить все прерывания на локальном процессоре. В противном случае, может возникнуть ситуация, когда обработчик прервет выполнение кода ядра, удерживающего блокировку, и снова попытается её захватить. При этом блокировка не освобождается, а обработчик прерывания в цикле начнет проверять, не освободилась ли нужная блокировка. С другой стороны, код ядра который удеживает блокировку, не сможет выполняться до завершения выполнения обработчика - они заблокируют друг друга.
Если блокировка реализуется в коде, выполняемом на однопроцессорной машине, то такая блокировка компилироваться не будет. Так, spin_lock_irqsave только запретит прерывания.

Следует отметить, что прерывания надо запрещать только на данном процессоре. Если прерывание возникает на другом процессоре по отношению к коду ядра, захватившему блокировку, и его обработчик будет ожидать освобождения блокировки, это не приведёт к дедлоку, так как первый процессор в конечном итоге освободит захваченную им блокировку.

Правило блокировки - необходимо защищать данные, а не код - блокировка всегда связана с данными.



30.05.15 ------------------------------------------------------------

test_and_set - атомарная команда, блокируется шина памяти. Спин-блокировка - более высокого уровня.
Если спин-блокировки использовать в обработчике прерываний, то перед захватыванием этой же блокировки в дрогом месте, необходимо запретить все локальные прерывания. В противном случае:
1. обработчик прерывания прерывает выполнения кода ядра, который уже удерживает блокировку;
2. обработчик пытается захватить эту же блокировку;
3. обработчик переходит в циклическое ожидание освобождения, но код не может выполниться
Получаем deadlock - двойной захват.
При этом прерывание нужно запрещать только на локальном процессоре.

Ядро предлагает интерфейс для одновременного захвата блокировок и запрета прерываний:
spinlock_t my_sp_lc = SPIN_LOCK_UNLOCKED;
unsigned long flags;
spin_lock_irqsave(&my_sp_lc, &flags);
	//критическая секция
spin_lock_irqrestore(&my_sp_lc, flags);
Должна быть чётко связана с тем, что блокирует; более важно запретить доступ к данным, а не к коду.
Если нужно гарантировать монопольное использование данных, то перед началом манипуляции над оными необходимо захватить соответствующую блокировку и освободить после завершения использования.
Если известно, что прерывания разрешены, то нет необходимости восстанавливать флаги.
spinlock_t sp = SPIN_LOCK_UNLOCKED
spun_lock_urq(&sp);
	//критическая секция
spin_unllock_irq(&sp);

Отладка спинлоков.
Параметр конфигурации ядра CONFIG_DEBUG_SPINLOCK включает несколько отладочных проверок. К примеру, в коде будут выполняться проверку на неинициализированные блокировки, а при захвате будет осуществляться проверка, была ли она уже захвачена.
Также CONFIG_DEBUG_LOCK_ALLOC

Спин-блокировка в нижних половинах
Тасклеты: одного типа - не могут выполняться параллельно, поэтому нет необходимости защищать используемые данные. Тем не менее, для тасклетов разного типа необходимо использовать обычную спин-блокировку. Запрещать обработчик нижней половины не надо, так как один замещает другой на том же процессоре.
soft irq: данные необходимо защищать в каждом случае, так софтирй одного типа могут выполняться параллельно. Но так как обработчики софтирй никогда не вытесняют другие обработчики прерываний, запрещать не надо.

	Семафоры в ядре
Использование семафоров связано с большими накладными расходами, что связано с переключением контекстов (2), поэтому их надо использовать только если длительность блокировки превышает длительность двух смен контекстов. Семафоры можно захватить только в контексте процессора (???)
Так как процессор может переходить в состояние ожидания (sleep) пытаясь захватить светофор ,...